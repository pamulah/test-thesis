{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_gridsearch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pamulah/test-thesis/blob/master/cnn_gridsearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hT7H1AgFX8wi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d5a9c1c-ecb1-4d2b-90af-395695352bd8"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class Histories(keras.callbacks.Callback):\n",
        "\tdef on_train_begin(self, logs={}):\n",
        "\t\tself.aucs = []\n",
        "\t\tself.losses = []\n",
        "\n",
        "\tdef on_train_end(self, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_begin(self, epoch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tself.losses.append(logs.get('loss'))\n",
        "\t\ty_pred = self.model.predict(self.validation_data[0])\n",
        "\t\tself.aucs.append(roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\ta = (roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\tprint(\" AUC_on_val: %f \" % a)\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_begin(self, batch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_end(self, batch, logs={}):    return\n",
        "  \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jUs78Pg157U2",
        "colab_type": "code",
        "outputId": "30539cb2-1531-4899-c663-74234d4c5d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''Example of how to use sklearn wrapper\n",
        "\n",
        "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import numpy\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "K.set_image_dim_ordering('th')\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from keras.datasets import mnist\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "# input image dimensions\n",
        "#img_rows, img_cols = 28, 28\n",
        "\n",
        "# load training data and do basic data normalization\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = numpy.load('drive/My Drive/X_train.npy')\n",
        "y_train = numpy.load('drive/My Drive/y_train.npy')\n",
        "X_test = numpy.load('drive/My Drive/X_test.npy')\n",
        "y_test = numpy.load('drive/My Drive/y_test.npy')\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 60, 87).astype('float32')\n",
        "#X_val = X_val.reshape(X_val.shape[0], 1, 60, 87).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 60, 87).astype('float32')\n",
        "\n",
        "\n",
        "'''if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255'''\n",
        "\n",
        "input_shape = (1, 60, 87)\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30581, 1, 60, 87) (30581,)\n",
            "(10793, 1, 60, 87) (10793,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXXL6keoH1l4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    #model.add(Activation('relu'))\n",
        "    #model.add(Conv2D(filters, kernel_size))\n",
        "    #model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    #for layer_size in dense_layer_sizes:\n",
        "    model.add(Dense(dense_layer_sizes))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDsoy0g8VlB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model_modified(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmUkJOKTM_Wo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def larger_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(20, (3,3), input_shape=(1, 60, 87), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Compile model\n",
        "  #model.compile(loss=roc_auc_score_loss, optimizer='adam', metrics=['accuracy','mae'])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YQJvxfSN1Iy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "#del model\n",
        "#dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
        "#model = make_model(5, 20, 3, 2)\n",
        "#model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "my_classifier = KerasClassifier(make_model_modified)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [128, 256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [15, 25, 40],\n",
        "                                     'filters': [20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     'batch_size': [32 , 64]}, \n",
        "                         scoring='neg_log_loss', n_jobs=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qC9TynBWTR0E",
        "colab_type": "code",
        "outputId": "4919743d-0263-4a39-a39c-e3cfac77a134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11092
        }
      },
      "cell_type": "code",
      "source": [
        "histories = Histories()\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',numpy.unique(y_train),y_train)\n",
        "print(class_weights)\n",
        "\n",
        "grid_result = validator.fit(X_train, y_train, class_weight = class_weights)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.50930984 27.35330948]\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 19s 937us/step - loss: 0.0784 - acc: 0.9887\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 17s 810us/step - loss: 0.0636 - acc: 0.9893\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 17s 821us/step - loss: 0.0623 - acc: 0.9893\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 17s 816us/step - loss: 0.0632 - acc: 0.9893\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 16s 809us/step - loss: 0.0624 - acc: 0.9893\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 17s 818us/step - loss: 0.0622 - acc: 0.9893\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 17s 825us/step - loss: 0.0614 - acc: 0.9893\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 17s 815us/step - loss: 0.0608 - acc: 0.9893\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 16s 803us/step - loss: 0.0611 - acc: 0.9893\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 16s 809us/step - loss: 0.0609 - acc: 0.9894\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 16s 807us/step - loss: 0.0618 - acc: 0.9894\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 16s 809us/step - loss: 0.0605 - acc: 0.9894\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 17s 849us/step - loss: 0.0606 - acc: 0.9894\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 17s 831us/step - loss: 0.0603 - acc: 0.9894\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 17s 816us/step - loss: 0.0606 - acc: 0.9894\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 18s 864us/step - loss: 0.1235 - acc: 0.9786\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 17s 832us/step - loss: 0.1071 - acc: 0.9793\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 18s 866us/step - loss: 0.1063 - acc: 0.9793\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 17s 836us/step - loss: 0.1058 - acc: 0.9793\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 18s 874us/step - loss: 0.1040 - acc: 0.9793\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 18s 865us/step - loss: 0.1037 - acc: 0.9793\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 17s 856us/step - loss: 0.1042 - acc: 0.9793\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 17s 848us/step - loss: 0.1040 - acc: 0.9793\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 18s 864us/step - loss: 0.1028 - acc: 0.9793\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 18s 873us/step - loss: 0.1034 - acc: 0.9794\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 17s 819us/step - loss: 0.1027 - acc: 0.9794\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 17s 814us/step - loss: 0.1035 - acc: 0.9794\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 17s 821us/step - loss: 0.1025 - acc: 0.9794\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 16s 804us/step - loss: 0.1010 - acc: 0.9794\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 15s 749us/step - loss: 0.0993 - acc: 0.9796\n",
            "Epoch 1/15\n",
            "20388/20388 [==============================] - 10s 499us/step - loss: 0.1279 - acc: 0.9764\n",
            "Epoch 2/15\n",
            "20388/20388 [==============================] - 10s 474us/step - loss: 0.1158 - acc: 0.9765\n",
            "Epoch 3/15\n",
            "20388/20388 [==============================] - 10s 471us/step - loss: 0.1161 - acc: 0.9765\n",
            "Epoch 4/15\n",
            "20388/20388 [==============================] - 10s 467us/step - loss: 0.1137 - acc: 0.9766\n",
            "Epoch 5/15\n",
            "20388/20388 [==============================] - 10s 467us/step - loss: 0.1142 - acc: 0.9765\n",
            "Epoch 6/15\n",
            "20388/20388 [==============================] - 10s 470us/step - loss: 0.1143 - acc: 0.9766\n",
            "Epoch 7/15\n",
            "20388/20388 [==============================] - 10s 486us/step - loss: 0.1124 - acc: 0.9766\n",
            "Epoch 8/15\n",
            "20388/20388 [==============================] - 10s 489us/step - loss: 0.1128 - acc: 0.9765\n",
            "Epoch 9/15\n",
            "20388/20388 [==============================] - 10s 489us/step - loss: 0.1120 - acc: 0.9766\n",
            "Epoch 10/15\n",
            "20388/20388 [==============================] - 10s 487us/step - loss: 0.1110 - acc: 0.9767\n",
            "Epoch 11/15\n",
            "20388/20388 [==============================] - 10s 485us/step - loss: 0.1103 - acc: 0.9768\n",
            "Epoch 12/15\n",
            "20388/20388 [==============================] - 10s 487us/step - loss: 0.1076 - acc: 0.9770\n",
            "Epoch 13/15\n",
            "20388/20388 [==============================] - 10s 488us/step - loss: 0.1088 - acc: 0.9776\n",
            "Epoch 14/15\n",
            "20388/20388 [==============================] - 10s 508us/step - loss: 0.0981 - acc: 0.9787\n",
            "Epoch 15/15\n",
            "20388/20388 [==============================] - 10s 497us/step - loss: 0.0895 - acc: 0.9808\n",
            "Epoch 1/25\n",
            "20387/20387 [==============================] - 11s 526us/step - loss: 0.0801 - acc: 0.9881\n",
            "Epoch 2/25\n",
            "20387/20387 [==============================] - 10s 506us/step - loss: 0.0652 - acc: 0.9893\n",
            "Epoch 3/25\n",
            "20387/20387 [==============================] - 10s 491us/step - loss: 0.0627 - acc: 0.9893\n",
            "Epoch 4/25\n",
            "20387/20387 [==============================] - 10s 489us/step - loss: 0.0634 - acc: 0.9893\n",
            "Epoch 5/25\n",
            "20387/20387 [==============================] - 10s 489us/step - loss: 0.0624 - acc: 0.9893\n",
            "Epoch 6/25\n",
            "20387/20387 [==============================] - 10s 503us/step - loss: 0.0620 - acc: 0.9894\n",
            "Epoch 7/25\n",
            "20387/20387 [==============================] - 10s 500us/step - loss: 0.0612 - acc: 0.9894\n",
            "Epoch 8/25\n",
            "20387/20387 [==============================] - 10s 487us/step - loss: 0.0610 - acc: 0.9894\n",
            "Epoch 9/25\n",
            "20387/20387 [==============================] - 10s 495us/step - loss: 0.0613 - acc: 0.9894\n",
            "Epoch 10/25\n",
            "20387/20387 [==============================] - 11s 533us/step - loss: 0.0606 - acc: 0.9895\n",
            "Epoch 11/25\n",
            "20387/20387 [==============================] - 10s 508us/step - loss: 0.0601 - acc: 0.9894\n",
            "Epoch 12/25\n",
            "20387/20387 [==============================] - 11s 519us/step - loss: 0.0607 - acc: 0.9894\n",
            "Epoch 13/25\n",
            "20387/20387 [==============================] - 11s 519us/step - loss: 0.0601 - acc: 0.9894\n",
            "Epoch 14/25\n",
            "20387/20387 [==============================] - 10s 515us/step - loss: 0.0603 - acc: 0.9895\n",
            "Epoch 15/25\n",
            "20387/20387 [==============================] - 10s 508us/step - loss: 0.0603 - acc: 0.9894\n",
            "Epoch 16/25\n",
            "20387/20387 [==============================] - 10s 499us/step - loss: 0.0602 - acc: 0.9895\n",
            "Epoch 17/25\n",
            "20387/20387 [==============================] - 10s 509us/step - loss: 0.0598 - acc: 0.9895\n",
            "Epoch 18/25\n",
            "20387/20387 [==============================] - 10s 495us/step - loss: 0.0595 - acc: 0.9894\n",
            "Epoch 19/25\n",
            "20387/20387 [==============================] - 10s 511us/step - loss: 0.0591 - acc: 0.9895\n",
            "Epoch 20/25\n",
            "20387/20387 [==============================] - 10s 512us/step - loss: 0.0582 - acc: 0.9896\n",
            "Epoch 21/25\n",
            "20387/20387 [==============================] - 10s 497us/step - loss: 0.0586 - acc: 0.9896\n",
            "Epoch 22/25\n",
            "20387/20387 [==============================] - 10s 494us/step - loss: 0.0580 - acc: 0.9895\n",
            "Epoch 23/25\n",
            "20387/20387 [==============================] - 10s 502us/step - loss: 0.0571 - acc: 0.9896\n",
            "Epoch 24/25\n",
            "20387/20387 [==============================] - 10s 500us/step - loss: 0.0565 - acc: 0.9896\n",
            "Epoch 25/25\n",
            "20387/20387 [==============================] - 10s 496us/step - loss: 0.0549 - acc: 0.9899\n",
            "Epoch 1/25\n",
            "20387/20387 [==============================] - 11s 535us/step - loss: 0.1182 - acc: 0.9792\n",
            "Epoch 2/25\n",
            "20387/20387 [==============================] - 10s 496us/step - loss: 0.1067 - acc: 0.9793\n",
            "Epoch 3/25\n",
            "20387/20387 [==============================] - 10s 498us/step - loss: 0.1062 - acc: 0.9793\n",
            "Epoch 4/25\n",
            "20387/20387 [==============================] - 10s 496us/step - loss: 0.1052 - acc: 0.9793\n",
            "Epoch 5/25\n",
            "20387/20387 [==============================] - 10s 493us/step - loss: 0.1056 - acc: 0.9793\n",
            "Epoch 6/25\n",
            "20387/20387 [==============================] - 10s 496us/step - loss: 0.1048 - acc: 0.9793\n",
            "Epoch 7/25\n",
            "20387/20387 [==============================] - 10s 494us/step - loss: 0.1027 - acc: 0.9793\n",
            "Epoch 8/25\n",
            "20387/20387 [==============================] - 10s 486us/step - loss: 0.1037 - acc: 0.9793\n",
            "Epoch 9/25\n",
            "20387/20387 [==============================] - 10s 490us/step - loss: 0.1035 - acc: 0.9794\n",
            "Epoch 10/25\n",
            "20387/20387 [==============================] - 10s 495us/step - loss: 0.1032 - acc: 0.9794\n",
            "Epoch 11/25\n",
            "20387/20387 [==============================] - 10s 510us/step - loss: 0.1025 - acc: 0.9793\n",
            "Epoch 12/25\n",
            "20387/20387 [==============================] - 10s 489us/step - loss: 0.1022 - acc: 0.9794\n",
            "Epoch 13/25\n",
            "20387/20387 [==============================] - 10s 495us/step - loss: 0.1014 - acc: 0.9793\n",
            "Epoch 14/25\n",
            "20387/20387 [==============================] - 10s 498us/step - loss: 0.1018 - acc: 0.9793\n",
            "Epoch 15/25\n",
            "20387/20387 [==============================] - 10s 502us/step - loss: 0.1019 - acc: 0.9794\n",
            "Epoch 16/25\n",
            "20387/20387 [==============================] - 11s 563us/step - loss: 0.0987 - acc: 0.9796\n",
            "Epoch 17/25\n",
            "20387/20387 [==============================] - 18s 886us/step - loss: 0.0964 - acc: 0.9798\n",
            "Epoch 18/25\n",
            "20387/20387 [==============================] - 11s 537us/step - loss: 0.0920 - acc: 0.9803\n",
            "Epoch 19/25\n",
            "20387/20387 [==============================] - 11s 536us/step - loss: 0.0854 - acc: 0.9819\n",
            "Epoch 20/25\n",
            "20387/20387 [==============================] - 11s 520us/step - loss: 0.0796 - acc: 0.9832\n",
            "Epoch 21/25\n",
            "20387/20387 [==============================] - 10s 514us/step - loss: 0.0710 - acc: 0.9840\n",
            "Epoch 22/25\n",
            "20387/20387 [==============================] - 10s 513us/step - loss: 0.0686 - acc: 0.9852\n",
            "Epoch 23/25\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.0609 - acc: 0.9866\n",
            "Epoch 24/25\n",
            "20387/20387 [==============================] - 10s 515us/step - loss: 0.0589 - acc: 0.9874\n",
            "Epoch 25/25\n",
            "20387/20387 [==============================] - 10s 514us/step - loss: 0.0565 - acc: 0.9880\n",
            "Epoch 1/25\n",
            "20388/20388 [==============================] - 11s 553us/step - loss: 0.1280 - acc: 0.9765\n",
            "Epoch 2/25\n",
            "20388/20388 [==============================] - 11s 522us/step - loss: 0.1157 - acc: 0.9765\n",
            "Epoch 3/25\n",
            "20388/20388 [==============================] - 11s 543us/step - loss: 0.1136 - acc: 0.9765\n",
            "Epoch 4/25\n",
            "20388/20388 [==============================] - 11s 528us/step - loss: 0.1137 - acc: 0.9765\n",
            "Epoch 5/25\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.1127 - acc: 0.9765\n",
            "Epoch 6/25\n",
            "20388/20388 [==============================] - 11s 531us/step - loss: 0.1110 - acc: 0.9765\n",
            "Epoch 7/25\n",
            "20388/20388 [==============================] - 10s 510us/step - loss: 0.1115 - acc: 0.9767\n",
            "Epoch 8/25\n",
            "20388/20388 [==============================] - 10s 504us/step - loss: 0.1081 - acc: 0.9770\n",
            "Epoch 9/25\n",
            "20388/20388 [==============================] - 10s 510us/step - loss: 0.0984 - acc: 0.9792\n",
            "Epoch 10/25\n",
            "20388/20388 [==============================] - 10s 512us/step - loss: 0.0911 - acc: 0.9809\n",
            "Epoch 11/25\n",
            "20388/20388 [==============================] - 11s 543us/step - loss: 0.0803 - acc: 0.9822\n",
            "Epoch 12/25\n",
            "20388/20388 [==============================] - 12s 567us/step - loss: 0.0827 - acc: 0.9823\n",
            "Epoch 13/25\n",
            "20388/20388 [==============================] - 11s 553us/step - loss: 0.0801 - acc: 0.9840\n",
            "Epoch 14/25\n",
            "20388/20388 [==============================] - 12s 568us/step - loss: 0.0737 - acc: 0.9843\n",
            "Epoch 15/25\n",
            "20388/20388 [==============================] - 12s 566us/step - loss: 0.0690 - acc: 0.9854\n",
            "Epoch 16/25\n",
            "20388/20388 [==============================] - 11s 557us/step - loss: 0.0663 - acc: 0.9866\n",
            "Epoch 17/25\n",
            "20388/20388 [==============================] - 11s 564us/step - loss: 0.0649 - acc: 0.9867\n",
            "Epoch 18/25\n",
            "20388/20388 [==============================] - 11s 539us/step - loss: 0.0651 - acc: 0.9866\n",
            "Epoch 19/25\n",
            "20388/20388 [==============================] - 11s 536us/step - loss: 0.0661 - acc: 0.9864\n",
            "Epoch 20/25\n",
            "20388/20388 [==============================] - 11s 558us/step - loss: 0.0678 - acc: 0.9867\n",
            "Epoch 21/25\n",
            "20388/20388 [==============================] - 12s 575us/step - loss: 0.0711 - acc: 0.9873\n",
            "Epoch 22/25\n",
            "20388/20388 [==============================] - 12s 574us/step - loss: 0.0655 - acc: 0.9874\n",
            "Epoch 23/25\n",
            "20388/20388 [==============================] - 12s 589us/step - loss: 0.0629 - acc: 0.9882\n",
            "Epoch 24/25\n",
            "20388/20388 [==============================] - 12s 587us/step - loss: 0.0583 - acc: 0.9890\n",
            "Epoch 25/25\n",
            "20388/20388 [==============================] - 12s 589us/step - loss: 0.0537 - acc: 0.9895\n",
            "Epoch 1/40\n",
            "20387/20387 [==============================] - 14s 682us/step - loss: 0.0774 - acc: 0.9890\n",
            "Epoch 2/40\n",
            "20387/20387 [==============================] - 13s 643us/step - loss: 0.0652 - acc: 0.9893\n",
            "Epoch 3/40\n",
            "20387/20387 [==============================] - 12s 604us/step - loss: 0.0646 - acc: 0.9893\n",
            "Epoch 4/40\n",
            "20387/20387 [==============================] - 11s 539us/step - loss: 0.0622 - acc: 0.9894\n",
            "Epoch 5/40\n",
            "20387/20387 [==============================] - 11s 555us/step - loss: 0.0622 - acc: 0.9893\n",
            "Epoch 6/40\n",
            "20387/20387 [==============================] - 11s 550us/step - loss: 0.0613 - acc: 0.9894\n",
            "Epoch 7/40\n",
            "20387/20387 [==============================] - 11s 530us/step - loss: 0.0613 - acc: 0.9894\n",
            "Epoch 8/40\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.0607 - acc: 0.9894\n",
            "Epoch 9/40\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.0609 - acc: 0.9893\n",
            "Epoch 10/40\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.0616 - acc: 0.9894\n",
            "Epoch 11/40\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.0608 - acc: 0.9894\n",
            "Epoch 12/40\n",
            "20387/20387 [==============================] - 11s 519us/step - loss: 0.0609 - acc: 0.9895\n",
            "Epoch 13/40\n",
            "20387/20387 [==============================] - 11s 519us/step - loss: 0.0610 - acc: 0.9894\n",
            "Epoch 14/40\n",
            "20387/20387 [==============================] - 11s 532us/step - loss: 0.0612 - acc: 0.9894\n",
            "Epoch 15/40\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.0601 - acc: 0.9895\n",
            "Epoch 16/40\n",
            "20387/20387 [==============================] - 11s 526us/step - loss: 0.0595 - acc: 0.9895\n",
            "Epoch 17/40\n",
            "20387/20387 [==============================] - 11s 536us/step - loss: 0.0593 - acc: 0.9895\n",
            "Epoch 18/40\n",
            "20387/20387 [==============================] - 11s 542us/step - loss: 0.0598 - acc: 0.9895\n",
            "Epoch 19/40\n",
            "20387/20387 [==============================] - 11s 519us/step - loss: 0.0596 - acc: 0.9895\n",
            "Epoch 20/40\n",
            "20387/20387 [==============================] - 11s 515us/step - loss: 0.0585 - acc: 0.9896\n",
            "Epoch 21/40\n",
            "20387/20387 [==============================] - 11s 537us/step - loss: 0.0605 - acc: 0.9895\n",
            "Epoch 22/40\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.0585 - acc: 0.9896\n",
            "Epoch 23/40\n",
            "20387/20387 [==============================] - 11s 544us/step - loss: 0.0587 - acc: 0.9896\n",
            "Epoch 24/40\n",
            "20387/20387 [==============================] - 12s 591us/step - loss: 0.0588 - acc: 0.9896\n",
            "Epoch 25/40\n",
            "20387/20387 [==============================] - 12s 610us/step - loss: 0.0559 - acc: 0.9897\n",
            "Epoch 26/40\n",
            "20387/20387 [==============================] - 12s 594us/step - loss: 0.0559 - acc: 0.9898\n",
            "Epoch 27/40\n",
            "20387/20387 [==============================] - 12s 581us/step - loss: 0.0547 - acc: 0.9901\n",
            "Epoch 28/40\n",
            "20387/20387 [==============================] - 11s 523us/step - loss: 0.0539 - acc: 0.9904\n",
            "Epoch 29/40\n",
            "20387/20387 [==============================] - 11s 551us/step - loss: 0.0513 - acc: 0.9908\n",
            "Epoch 30/40\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0465 - acc: 0.9910\n",
            "Epoch 31/40\n",
            "20387/20387 [==============================] - 11s 515us/step - loss: 0.0484 - acc: 0.9910\n",
            "Epoch 32/40\n",
            "20387/20387 [==============================] - 11s 536us/step - loss: 0.0461 - acc: 0.9918\n",
            "Epoch 33/40\n",
            "20387/20387 [==============================] - 12s 567us/step - loss: 0.0429 - acc: 0.9920\n",
            "Epoch 34/40\n",
            "20387/20387 [==============================] - 11s 553us/step - loss: 0.0437 - acc: 0.9920\n",
            "Epoch 35/40\n",
            "20387/20387 [==============================] - 11s 549us/step - loss: 0.0424 - acc: 0.9920\n",
            "Epoch 36/40\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.0419 - acc: 0.9924\n",
            "Epoch 37/40\n",
            "20387/20387 [==============================] - 11s 544us/step - loss: 0.0405 - acc: 0.9926\n",
            "Epoch 38/40\n",
            "20387/20387 [==============================] - 11s 545us/step - loss: 0.0446 - acc: 0.9922\n",
            "Epoch 39/40\n",
            "20387/20387 [==============================] - 11s 533us/step - loss: 0.0417 - acc: 0.9927\n",
            "Epoch 40/40\n",
            "20387/20387 [==============================] - 11s 533us/step - loss: 0.0386 - acc: 0.9925\n",
            "Epoch 1/40\n",
            "20387/20387 [==============================] - 13s 650us/step - loss: 0.1196 - acc: 0.9787\n",
            "Epoch 2/40\n",
            "20387/20387 [==============================] - 12s 588us/step - loss: 0.1068 - acc: 0.9793\n",
            "Epoch 3/40\n",
            "20387/20387 [==============================] - 11s 564us/step - loss: 0.1070 - acc: 0.9793\n",
            "Epoch 4/40\n",
            "20387/20387 [==============================] - 11s 550us/step - loss: 0.1062 - acc: 0.9793\n",
            "Epoch 5/40\n",
            "20387/20387 [==============================] - 11s 533us/step - loss: 0.1048 - acc: 0.9793\n",
            "Epoch 6/40\n",
            "20387/20387 [==============================] - 11s 533us/step - loss: 0.1051 - acc: 0.9793\n",
            "Epoch 7/40\n",
            "20387/20387 [==============================] - 11s 531us/step - loss: 0.1041 - acc: 0.9793\n",
            "Epoch 8/40\n",
            "20387/20387 [==============================] - 11s 548us/step - loss: 0.1030 - acc: 0.9793\n",
            "Epoch 9/40\n",
            "20387/20387 [==============================] - 11s 531us/step - loss: 0.1041 - acc: 0.9793\n",
            "Epoch 10/40\n",
            "20387/20387 [==============================] - 11s 536us/step - loss: 0.1034 - acc: 0.9794\n",
            "Epoch 11/40\n",
            "20387/20387 [==============================] - 11s 520us/step - loss: 0.1023 - acc: 0.9794\n",
            "Epoch 12/40\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.1017 - acc: 0.9794\n",
            "Epoch 13/40\n",
            "20387/20387 [==============================] - 11s 521us/step - loss: 0.1025 - acc: 0.9793\n",
            "Epoch 14/40\n",
            "20387/20387 [==============================] - 11s 532us/step - loss: 0.1008 - acc: 0.9794\n",
            "Epoch 15/40\n",
            "20387/20387 [==============================] - 11s 517us/step - loss: 0.1011 - acc: 0.9795\n",
            "Epoch 16/40\n",
            "20387/20387 [==============================] - 11s 516us/step - loss: 0.0981 - acc: 0.9802\n",
            "Epoch 17/40\n",
            "20387/20387 [==============================] - 11s 528us/step - loss: 0.0962 - acc: 0.9810\n",
            "Epoch 18/40\n",
            "20387/20387 [==============================] - 10s 515us/step - loss: 0.0869 - acc: 0.9823\n",
            "Epoch 19/40\n",
            "20387/20387 [==============================] - 11s 517us/step - loss: 0.0765 - acc: 0.9834\n",
            "Epoch 20/40\n",
            "20387/20387 [==============================] - 11s 534us/step - loss: 0.0763 - acc: 0.9837\n",
            "Epoch 21/40\n",
            "20387/20387 [==============================] - 11s 545us/step - loss: 0.0701 - acc: 0.9850\n",
            "Epoch 22/40\n",
            "20387/20387 [==============================] - 10s 510us/step - loss: 0.0636 - acc: 0.9863\n",
            "Epoch 23/40\n",
            "20387/20387 [==============================] - 10s 513us/step - loss: 0.0615 - acc: 0.9870\n",
            "Epoch 24/40\n",
            "20387/20387 [==============================] - 12s 575us/step - loss: 0.0595 - acc: 0.9875\n",
            "Epoch 25/40\n",
            "20387/20387 [==============================] - 11s 541us/step - loss: 0.0551 - acc: 0.9881\n",
            "Epoch 26/40\n",
            "20387/20387 [==============================] - 12s 612us/step - loss: 0.0561 - acc: 0.9887\n",
            "Epoch 27/40\n",
            "20387/20387 [==============================] - 12s 603us/step - loss: 0.0540 - acc: 0.9890\n",
            "Epoch 28/40\n",
            "20387/20387 [==============================] - 12s 605us/step - loss: 0.0581 - acc: 0.9883\n",
            "Epoch 29/40\n",
            "20387/20387 [==============================] - 13s 616us/step - loss: 0.0507 - acc: 0.9895\n",
            "Epoch 30/40\n",
            "20387/20387 [==============================] - 12s 611us/step - loss: 0.0480 - acc: 0.9899\n",
            "Epoch 31/40\n",
            "20387/20387 [==============================] - 13s 647us/step - loss: 0.0461 - acc: 0.9900\n",
            "Epoch 32/40\n",
            "20387/20387 [==============================] - 11s 545us/step - loss: 0.0450 - acc: 0.9902\n",
            "Epoch 33/40\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0453 - acc: 0.9908\n",
            "Epoch 34/40\n",
            "20387/20387 [==============================] - 10s 513us/step - loss: 0.0405 - acc: 0.9911\n",
            "Epoch 35/40\n",
            "20387/20387 [==============================] - 11s 517us/step - loss: 0.0408 - acc: 0.9911\n",
            "Epoch 36/40\n",
            "20387/20387 [==============================] - 10s 513us/step - loss: 0.0393 - acc: 0.9914\n",
            "Epoch 37/40\n",
            "20387/20387 [==============================] - 10s 510us/step - loss: 0.0373 - acc: 0.9917\n",
            "Epoch 38/40\n",
            "20387/20387 [==============================] - 11s 517us/step - loss: 0.0366 - acc: 0.9920\n",
            "Epoch 39/40\n",
            "20387/20387 [==============================] - 10s 507us/step - loss: 0.0336 - acc: 0.9924\n",
            "Epoch 40/40\n",
            "20387/20387 [==============================] - 10s 503us/step - loss: 0.0337 - acc: 0.9926\n",
            "Epoch 1/40\n",
            "20388/20388 [==============================] - 12s 584us/step - loss: 0.1284 - acc: 0.9759\n",
            "Epoch 2/40\n",
            "20388/20388 [==============================] - 11s 541us/step - loss: 0.1159 - acc: 0.9765\n",
            "Epoch 3/40\n",
            "20388/20388 [==============================] - 11s 520us/step - loss: 0.1137 - acc: 0.9765\n",
            "Epoch 4/40\n",
            "20388/20388 [==============================] - 11s 521us/step - loss: 0.1149 - acc: 0.9765\n",
            "Epoch 5/40\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.1134 - acc: 0.9765\n",
            "Epoch 6/40\n",
            "20388/20388 [==============================] - 11s 523us/step - loss: 0.1138 - acc: 0.9766\n",
            "Epoch 7/40\n",
            "20388/20388 [==============================] - 10s 512us/step - loss: 0.1114 - acc: 0.9766\n",
            "Epoch 8/40\n",
            "20388/20388 [==============================] - 10s 502us/step - loss: 0.1119 - acc: 0.9766\n",
            "Epoch 9/40\n",
            "20388/20388 [==============================] - 10s 503us/step - loss: 0.1127 - acc: 0.9765\n",
            "Epoch 10/40\n",
            "20388/20388 [==============================] - 10s 507us/step - loss: 0.1108 - acc: 0.9768\n",
            "Epoch 11/40\n",
            "20388/20388 [==============================] - 11s 535us/step - loss: 0.1093 - acc: 0.9769\n",
            "Epoch 12/40\n",
            "20388/20388 [==============================] - 11s 555us/step - loss: 0.1096 - acc: 0.9770\n",
            "Epoch 13/40\n",
            "20388/20388 [==============================] - 11s 549us/step - loss: 0.1084 - acc: 0.9770\n",
            "Epoch 14/40\n",
            "20388/20388 [==============================] - 11s 557us/step - loss: 0.1092 - acc: 0.9773\n",
            "Epoch 15/40\n",
            "20388/20388 [==============================] - 11s 557us/step - loss: 0.1068 - acc: 0.9777\n",
            "Epoch 16/40\n",
            "20388/20388 [==============================] - 11s 538us/step - loss: 0.1032 - acc: 0.9789\n",
            "Epoch 17/40\n",
            "20388/20388 [==============================] - 11s 552us/step - loss: 0.0927 - acc: 0.9802\n",
            "Epoch 18/40\n",
            "20388/20388 [==============================] - 11s 543us/step - loss: 0.0895 - acc: 0.9808\n",
            "Epoch 19/40\n",
            "20388/20388 [==============================] - 11s 541us/step - loss: 0.0757 - acc: 0.9830\n",
            "Epoch 20/40\n",
            "20388/20388 [==============================] - 11s 528us/step - loss: 0.0742 - acc: 0.9840\n",
            "Epoch 21/40\n",
            "20388/20388 [==============================] - 11s 550us/step - loss: 0.0695 - acc: 0.9849\n",
            "Epoch 22/40\n",
            "20388/20388 [==============================] - 11s 544us/step - loss: 0.0635 - acc: 0.9867\n",
            "Epoch 23/40\n",
            "20388/20388 [==============================] - 11s 544us/step - loss: 0.0599 - acc: 0.9872\n",
            "Epoch 24/40\n",
            "20388/20388 [==============================] - 11s 523us/step - loss: 0.0559 - acc: 0.9885\n",
            "Epoch 25/40\n",
            "20388/20388 [==============================] - 11s 522us/step - loss: 0.0582 - acc: 0.9879\n",
            "Epoch 26/40\n",
            "20388/20388 [==============================] - 11s 526us/step - loss: 0.0522 - acc: 0.9892\n",
            "Epoch 27/40\n",
            "20388/20388 [==============================] - 11s 524us/step - loss: 0.0498 - acc: 0.9896\n",
            "Epoch 28/40\n",
            "20388/20388 [==============================] - 11s 523us/step - loss: 0.0500 - acc: 0.9895\n",
            "Epoch 29/40\n",
            "20388/20388 [==============================] - 11s 525us/step - loss: 0.0493 - acc: 0.9897\n",
            "Epoch 30/40\n",
            "20388/20388 [==============================] - 10s 507us/step - loss: 0.0489 - acc: 0.9899\n",
            "Epoch 31/40\n",
            "20388/20388 [==============================] - 10s 511us/step - loss: 0.0446 - acc: 0.9905\n",
            "Epoch 32/40\n",
            "20388/20388 [==============================] - 10s 511us/step - loss: 0.0401 - acc: 0.9915\n",
            "Epoch 33/40\n",
            "20388/20388 [==============================] - 10s 514us/step - loss: 0.0416 - acc: 0.9913\n",
            "Epoch 34/40\n",
            "20388/20388 [==============================] - 11s 515us/step - loss: 0.0417 - acc: 0.9911\n",
            "Epoch 35/40\n",
            "20388/20388 [==============================] - 10s 513us/step - loss: 0.0372 - acc: 0.9923\n",
            "Epoch 36/40\n",
            "20388/20388 [==============================] - 10s 509us/step - loss: 0.0392 - acc: 0.9920\n",
            "Epoch 37/40\n",
            "20388/20388 [==============================] - 10s 508us/step - loss: 0.0358 - acc: 0.9925\n",
            "Epoch 38/40\n",
            "20388/20388 [==============================] - 10s 513us/step - loss: 0.0321 - acc: 0.9932\n",
            "Epoch 39/40\n",
            "20388/20388 [==============================] - 10s 513us/step - loss: 0.0309 - acc: 0.9935\n",
            "Epoch 40/40\n",
            "20388/20388 [==============================] - 10s 511us/step - loss: 0.0319 - acc: 0.9936\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 12s 568us/step - loss: 0.1799 - acc: 0.9892\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 10s 513us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 11s 521us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 11s 526us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 10s 513us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 11s 515us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 11s 559us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 11s 538us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 11s 545us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 10s 514us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 10s 510us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 10s 512us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 10s 514us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 11s 553us/step - loss: 0.1724 - acc: 0.9893\n",
            "Epoch 1/15\n",
            "20387/20387 [==============================] - 13s 637us/step - loss: 0.1181 - acc: 0.9789\n",
            "Epoch 2/15\n",
            "20387/20387 [==============================] - 11s 555us/step - loss: 0.1055 - acc: 0.9793\n",
            "Epoch 3/15\n",
            "20387/20387 [==============================] - 11s 549us/step - loss: 0.1074 - acc: 0.9793\n",
            "Epoch 4/15\n",
            "20387/20387 [==============================] - 11s 558us/step - loss: 0.1045 - acc: 0.9793\n",
            "Epoch 5/15\n",
            "20387/20387 [==============================] - 11s 536us/step - loss: 0.1055 - acc: 0.9793\n",
            "Epoch 6/15\n",
            "20387/20387 [==============================] - 11s 533us/step - loss: 0.1053 - acc: 0.9794\n",
            "Epoch 7/15\n",
            "20387/20387 [==============================] - 11s 546us/step - loss: 0.1052 - acc: 0.9793\n",
            "Epoch 8/15\n",
            "20387/20387 [==============================] - 11s 559us/step - loss: 0.1044 - acc: 0.9793\n",
            "Epoch 9/15\n",
            "20387/20387 [==============================] - 11s 561us/step - loss: 0.1047 - acc: 0.9794\n",
            "Epoch 10/15\n",
            "20387/20387 [==============================] - 11s 550us/step - loss: 0.1042 - acc: 0.9793\n",
            "Epoch 11/15\n",
            "20387/20387 [==============================] - 11s 544us/step - loss: 0.1040 - acc: 0.9793\n",
            "Epoch 12/15\n",
            "20387/20387 [==============================] - 11s 544us/step - loss: 0.1029 - acc: 0.9793\n",
            "Epoch 13/15\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.1041 - acc: 0.9794\n",
            "Epoch 14/15\n",
            "20387/20387 [==============================] - 11s 527us/step - loss: 0.1026 - acc: 0.9794\n",
            "Epoch 15/15\n",
            "20387/20387 [==============================] - 11s 528us/step - loss: 0.1032 - acc: 0.9794\n",
            "Epoch 1/15\n",
            "20388/20388 [==============================] - 12s 594us/step - loss: 0.1238 - acc: 0.9759\n",
            "Epoch 2/15\n",
            "20388/20388 [==============================] - 10s 512us/step - loss: 0.1162 - acc: 0.9765\n",
            "Epoch 3/15\n",
            "20388/20388 [==============================] - 10s 508us/step - loss: 0.1146 - acc: 0.9765\n",
            "Epoch 4/15\n",
            "20388/20388 [==============================] - 11s 527us/step - loss: 0.1143 - acc: 0.9765\n",
            "Epoch 5/15\n",
            "20388/20388 [==============================] - 10s 513us/step - loss: 0.1136 - acc: 0.9765\n",
            "Epoch 6/15\n",
            "20388/20388 [==============================] - 10s 513us/step - loss: 0.1127 - acc: 0.9765\n",
            "Epoch 7/15\n",
            "20388/20388 [==============================] - 10s 511us/step - loss: 0.1134 - acc: 0.9767\n",
            "Epoch 8/15\n",
            "20388/20388 [==============================] - 10s 506us/step - loss: 0.1115 - acc: 0.9768\n",
            "Epoch 9/15\n",
            "20388/20388 [==============================] - 10s 506us/step - loss: 0.1120 - acc: 0.9768\n",
            "Epoch 10/15\n",
            "20388/20388 [==============================] - 10s 509us/step - loss: 0.1100 - acc: 0.9770\n",
            "Epoch 11/15\n",
            "20388/20388 [==============================] - 10s 509us/step - loss: 0.1053 - acc: 0.9779\n",
            "Epoch 12/15\n",
            "20388/20388 [==============================] - 10s 507us/step - loss: 0.0994 - acc: 0.9797\n",
            "Epoch 13/15\n",
            "20388/20388 [==============================] - 10s 508us/step - loss: 0.0941 - acc: 0.9811\n",
            "Epoch 14/15\n",
            "20388/20388 [==============================] - 10s 504us/step - loss: 0.0811 - acc: 0.9824\n",
            "Epoch 15/15\n",
            "20388/20388 [==============================] - 10s 502us/step - loss: 0.0752 - acc: 0.9843\n",
            "Epoch 1/25\n",
            "20387/20387 [==============================] - 12s 578us/step - loss: 0.0739 - acc: 0.9892\n",
            "Epoch 2/25\n",
            "20387/20387 [==============================] - 10s 506us/step - loss: 0.0645 - acc: 0.9893\n",
            "Epoch 3/25\n",
            "20387/20387 [==============================] - 10s 505us/step - loss: 0.0635 - acc: 0.9893\n",
            "Epoch 4/25\n",
            "20387/20387 [==============================] - 10s 511us/step - loss: 0.0623 - acc: 0.9893\n",
            "Epoch 5/25\n",
            "20387/20387 [==============================] - 11s 524us/step - loss: 0.0619 - acc: 0.9893\n",
            "Epoch 6/25\n",
            "20387/20387 [==============================] - 11s 522us/step - loss: 0.0617 - acc: 0.9893\n",
            "Epoch 7/25\n",
            "20387/20387 [==============================] - 11s 537us/step - loss: 0.0619 - acc: 0.9894\n",
            "Epoch 8/25\n",
            "20387/20387 [==============================] - 10s 510us/step - loss: 0.0606 - acc: 0.9894\n",
            "Epoch 9/25\n",
            "20387/20387 [==============================] - 10s 508us/step - loss: 0.0606 - acc: 0.9894\n",
            "Epoch 10/25\n",
            "20387/20387 [==============================] - 10s 504us/step - loss: 0.0608 - acc: 0.9894\n",
            "Epoch 11/25\n",
            "20387/20387 [==============================] - 10s 503us/step - loss: 0.0600 - acc: 0.9894\n",
            "Epoch 12/25\n",
            "20387/20387 [==============================] - 10s 511us/step - loss: 0.0604 - acc: 0.9894\n",
            "Epoch 13/25\n",
            "20387/20387 [==============================] - 11s 517us/step - loss: 0.0597 - acc: 0.9894\n",
            "Epoch 14/25\n",
            "20387/20387 [==============================] - 11s 526us/step - loss: 0.0595 - acc: 0.9894\n",
            "Epoch 15/25\n",
            "20387/20387 [==============================] - 11s 553us/step - loss: 0.0600 - acc: 0.9895\n",
            "Epoch 16/25\n",
            "16192/20387 [======================>.......] - ETA: 2s - loss: 0.0605 - acc: 0.9891Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i_sHRwZ5UZ9h",
        "colab_type": "code",
        "outputId": "3e072b22-e9fa-4bc7-871d-9baedb94f176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)\n",
        "\n",
        "best_model = validator.best_estimator_.model\n",
        "metric_names = best_model.metrics_names\n",
        "metric_values = best_model.evaluate(X_test, y_test)\n",
        "for metric, value in zip(metric_names, metric_values):\n",
        "  print(metric, ': ', value)\n",
        "  \n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "  \n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters of the best model are: \n",
            "{'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "10793/10793 [==============================] - 4s 390us/step\n",
            "loss :  0.2187956089200402\n",
            "acc :  0.9502455295098675\n",
            "-0.103548 (0.042176) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.117072 (0.049676) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 25, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.139923 (0.059000) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 40, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.449941 (0.499338) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.122406 (0.050066) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 25, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.427351 (0.514898) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 40, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.094667 (0.042315) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.095829 (0.049519) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 25, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.123953 (0.055634) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 40, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.109917 (0.043461) with: {'batch_size': 64, 'dense_layer_sizes': 256, 'epochs': 15, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.124791 (0.051135) with: {'batch_size': 64, 'dense_layer_sizes': 256, 'epochs': 25, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "-0.101512 (0.043462) with: {'batch_size': 64, 'dense_layer_sizes': 256, 'epochs': 40, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NvvRbL1KPSSK",
        "colab_type": "code",
        "outputId": "205a98ca-47b2-4432-e0e9-834de4be4c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate AUC of final model on a test set\n",
        "probs = best_model.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "#probs = probs[:, 1]\n",
        "y_test2 = numpy.load('drive/My Drive/y_test.npy')  # osobno, bo inny wymiar\n",
        "\n",
        "auc = roc_auc_score(y_test2, probs)\n",
        "print('AUC: %.3f' % auc)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, probs)\n",
        "# plot no skill\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr, tpr, marker='.')\n",
        "# show the plot\n",
        "plt.title('ROC curve for test set')\n",
        "pyplot.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJGEJExERSfL/a8MnDncr2aQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f19de7ddc88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aOXKJUC-bjnb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}