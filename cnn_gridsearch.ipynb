{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_gridsearch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pamulah/test-thesis/blob/master/cnn_gridsearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hT7H1AgFX8wi",
        "colab_type": "code",
        "outputId": "85d3331c-87a6-4b0c-f141-aeaf3c96d221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class Histories(keras.callbacks.Callback):\n",
        "\tdef on_train_begin(self, logs={}):\n",
        "\t\tself.aucs = []\n",
        "\t\tself.losses = []\n",
        "\n",
        "\tdef on_train_end(self, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_begin(self, epoch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tself.losses.append(logs.get('loss'))\n",
        "\t\ty_pred = self.model.predict(self.validation_data[0])\n",
        "\t\tself.aucs.append(roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\ta = (roc_auc_score(self.validation_data[1], y_pred))\n",
        "\t\tprint(\" AUC_on_val: %f \" % a)\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_begin(self, batch, logs={}):\n",
        "\t\treturn\n",
        "\n",
        "\tdef on_batch_end(self, batch, logs={}):    return\n",
        "  \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jUs78Pg157U2",
        "colab_type": "code",
        "outputId": "a8c1088e-e908-4b95-ca8c-fe5c088a8725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''Example of how to use sklearn wrapper\n",
        "\n",
        "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import numpy\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "K.set_image_dim_ordering('th')\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from keras.datasets import mnist\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "# input image dimensions\n",
        "#img_rows, img_cols = 28, 28\n",
        "\n",
        "# load training data and do basic data normalization\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = numpy.load('drive/My Drive/X_train.npy')\n",
        "y_train = numpy.load('drive/My Drive/y_train.npy')\n",
        "X_test = numpy.load('drive/My Drive/X_test.npy')\n",
        "y_test = numpy.load('drive/My Drive/y_test.npy')\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 60, 87).astype('float32')\n",
        "#X_val = X_val.reshape(X_val.shape[0], 1, 60, 87).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 60, 87).astype('float32')\n",
        "\n",
        "\n",
        "'''if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255'''\n",
        "\n",
        "input_shape = (1, 60, 87)\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30581, 1, 60, 87) (30581,)\n",
            "(10793, 1, 60, 87) (10793,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXXL6keoH1l4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    #model.add(Activation('relu'))\n",
        "    #model.add(Conv2D(filters, kernel_size))\n",
        "    #model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    #for layer_size in dense_layer_sizes:\n",
        "    model.add(Dense(dense_layer_sizes))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDsoy0g8VlB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model_modified(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmUkJOKTM_Wo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def larger_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(20, (3,3), input_shape=(1, 60, 87), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Compile model\n",
        "  #model.compile(loss=roc_auc_score_loss, optimizer='adam', metrics=['accuracy','mae'])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YQJvxfSN1Iy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "#del model\n",
        "#dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
        "#model = make_model(5, 20, 3, 2)\n",
        "#model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "my_classifier = KerasClassifier(make_model_modified)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [40],\n",
        "                                     'filters': [20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     'batch_size': [32]}, \n",
        "                         scoring='neg_log_loss', n_jobs=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qC9TynBWTR0E",
        "colab_type": "code",
        "outputId": "80799d56-7e8a-445c-cb06-596577df89ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5913
        }
      },
      "cell_type": "code",
      "source": [
        "histories = Histories()\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',numpy.unique(y_train),y_train)\n",
        "print(class_weights)\n",
        "\n",
        "grid_result = validator.fit(X_train, y_train, class_weight = class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.50930984 27.35330948]\n",
            "Epoch 1/40\n",
            "20387/20387 [==============================] - 11s 518us/step - loss: 0.0791 - acc: 0.9885\n",
            "Epoch 2/40\n",
            "20387/20387 [==============================] - 10s 471us/step - loss: 0.0646 - acc: 0.9893\n",
            "Epoch 3/40\n",
            "20387/20387 [==============================] - 10s 470us/step - loss: 0.0625 - acc: 0.9893\n",
            "Epoch 4/40\n",
            "20387/20387 [==============================] - 10s 477us/step - loss: 0.0625 - acc: 0.9893\n",
            "Epoch 5/40\n",
            "20387/20387 [==============================] - 10s 469us/step - loss: 0.0626 - acc: 0.9893\n",
            "Epoch 6/40\n",
            "20387/20387 [==============================] - 10s 476us/step - loss: 0.0623 - acc: 0.9893\n",
            "Epoch 7/40\n",
            "20387/20387 [==============================] - 10s 477us/step - loss: 0.0629 - acc: 0.9893\n",
            "Epoch 8/40\n",
            "20387/20387 [==============================] - 10s 472us/step - loss: 0.0617 - acc: 0.9893\n",
            "Epoch 9/40\n",
            "20387/20387 [==============================] - 9s 463us/step - loss: 0.0622 - acc: 0.9894\n",
            "Epoch 10/40\n",
            "20387/20387 [==============================] - 10s 468us/step - loss: 0.0620 - acc: 0.9894\n",
            "Epoch 11/40\n",
            "20387/20387 [==============================] - 9s 463us/step - loss: 0.0612 - acc: 0.9894\n",
            "Epoch 12/40\n",
            "20387/20387 [==============================] - 9s 450us/step - loss: 0.0607 - acc: 0.9894\n",
            "Epoch 13/40\n",
            "20387/20387 [==============================] - 9s 454us/step - loss: 0.0608 - acc: 0.9894\n",
            "Epoch 14/40\n",
            "20387/20387 [==============================] - 9s 457us/step - loss: 0.0609 - acc: 0.9894\n",
            "Epoch 15/40\n",
            "20387/20387 [==============================] - 9s 456us/step - loss: 0.0603 - acc: 0.9894\n",
            "Epoch 16/40\n",
            "20387/20387 [==============================] - 9s 452us/step - loss: 0.0616 - acc: 0.9894\n",
            "Epoch 17/40\n",
            "20387/20387 [==============================] - 9s 456us/step - loss: 0.0613 - acc: 0.9895\n",
            "Epoch 18/40\n",
            "20387/20387 [==============================] - 9s 454us/step - loss: 0.0609 - acc: 0.9894\n",
            "Epoch 19/40\n",
            "20387/20387 [==============================] - 9s 451us/step - loss: 0.0596 - acc: 0.9894\n",
            "Epoch 20/40\n",
            "20387/20387 [==============================] - 9s 454us/step - loss: 0.0597 - acc: 0.9895\n",
            "Epoch 21/40\n",
            "20387/20387 [==============================] - 9s 462us/step - loss: 0.0590 - acc: 0.9895\n",
            "Epoch 22/40\n",
            "20387/20387 [==============================] - 9s 451us/step - loss: 0.0586 - acc: 0.9895\n",
            "Epoch 23/40\n",
            "20387/20387 [==============================] - 9s 447us/step - loss: 0.0591 - acc: 0.9895\n",
            "Epoch 24/40\n",
            "20387/20387 [==============================] - 9s 456us/step - loss: 0.0601 - acc: 0.9894\n",
            "Epoch 25/40\n",
            "20387/20387 [==============================] - 9s 455us/step - loss: 0.0586 - acc: 0.9895\n",
            "Epoch 26/40\n",
            "20387/20387 [==============================] - 9s 447us/step - loss: 0.0591 - acc: 0.9895\n",
            "Epoch 27/40\n",
            "20387/20387 [==============================] - 9s 452us/step - loss: 0.0586 - acc: 0.9895\n",
            "Epoch 28/40\n",
            "20387/20387 [==============================] - 9s 456us/step - loss: 0.0596 - acc: 0.9895\n",
            "Epoch 29/40\n",
            "20387/20387 [==============================] - 9s 448us/step - loss: 0.0583 - acc: 0.9895\n",
            "Epoch 30/40\n",
            "20387/20387 [==============================] - 9s 447us/step - loss: 0.0578 - acc: 0.9896\n",
            "Epoch 31/40\n",
            "20387/20387 [==============================] - 9s 450us/step - loss: 0.0569 - acc: 0.9897\n",
            "Epoch 32/40\n",
            "20387/20387 [==============================] - 9s 449us/step - loss: 0.0565 - acc: 0.9897\n",
            "Epoch 33/40\n",
            "20387/20387 [==============================] - 9s 442us/step - loss: 0.0557 - acc: 0.9900\n",
            "Epoch 34/40\n",
            "20387/20387 [==============================] - 9s 446us/step - loss: 0.0552 - acc: 0.9900\n",
            "Epoch 35/40\n",
            "20387/20387 [==============================] - 9s 453us/step - loss: 0.0530 - acc: 0.9902\n",
            "Epoch 36/40\n",
            "20387/20387 [==============================] - 9s 447us/step - loss: 0.0506 - acc: 0.9906\n",
            "Epoch 37/40\n",
            "20387/20387 [==============================] - 9s 445us/step - loss: 0.0505 - acc: 0.9907\n",
            "Epoch 38/40\n",
            "20387/20387 [==============================] - 9s 448us/step - loss: 0.0503 - acc: 0.9908\n",
            "Epoch 39/40\n",
            "20387/20387 [==============================] - 9s 450us/step - loss: 0.0481 - acc: 0.9914\n",
            "Epoch 40/40\n",
            "20387/20387 [==============================] - 9s 446us/step - loss: 0.0474 - acc: 0.9913\n",
            "Epoch 1/40\n",
            "20387/20387 [==============================] - 10s 482us/step - loss: 0.1192 - acc: 0.9792\n",
            "Epoch 2/40\n",
            "20387/20387 [==============================] - 9s 452us/step - loss: 0.1063 - acc: 0.9793\n",
            "Epoch 3/40\n",
            "20387/20387 [==============================] - 9s 451us/step - loss: 0.1053 - acc: 0.9793\n",
            "Epoch 4/40\n",
            "20387/20387 [==============================] - 9s 447us/step - loss: 0.1040 - acc: 0.9793\n",
            "Epoch 5/40\n",
            "20387/20387 [==============================] - 9s 446us/step - loss: 0.1066 - acc: 0.9793\n",
            "Epoch 6/40\n",
            "20387/20387 [==============================] - 9s 452us/step - loss: 0.1049 - acc: 0.9793\n",
            "Epoch 7/40\n",
            "20387/20387 [==============================] - 9s 450us/step - loss: 0.1043 - acc: 0.9793\n",
            "Epoch 8/40\n",
            "20387/20387 [==============================] - 9s 449us/step - loss: 0.1033 - acc: 0.9794\n",
            "Epoch 9/40\n",
            "20387/20387 [==============================] - 9s 449us/step - loss: 0.1033 - acc: 0.9794\n",
            "Epoch 10/40\n",
            "20387/20387 [==============================] - 9s 449us/step - loss: 0.1024 - acc: 0.9794\n",
            "Epoch 11/40\n",
            "20387/20387 [==============================] - 9s 444us/step - loss: 0.1031 - acc: 0.9793\n",
            "Epoch 12/40\n",
            "20387/20387 [==============================] - 9s 442us/step - loss: 0.1035 - acc: 0.9794\n",
            "Epoch 13/40\n",
            "20387/20387 [==============================] - 9s 450us/step - loss: 0.1005 - acc: 0.9794\n",
            "Epoch 14/40\n",
            "20387/20387 [==============================] - 9s 463us/step - loss: 0.0979 - acc: 0.9803\n",
            "Epoch 15/40\n",
            "20387/20387 [==============================] - 9s 461us/step - loss: 0.0892 - acc: 0.9817\n",
            "Epoch 16/40\n",
            "20387/20387 [==============================] - 9s 458us/step - loss: 0.0795 - acc: 0.9830\n",
            "Epoch 17/40\n",
            "20387/20387 [==============================] - 10s 467us/step - loss: 0.0694 - acc: 0.9844\n",
            "Epoch 18/40\n",
            "20387/20387 [==============================] - 9s 465us/step - loss: 0.0627 - acc: 0.9860\n",
            "Epoch 19/40\n",
            "20387/20387 [==============================] - 9s 458us/step - loss: 0.0633 - acc: 0.9862\n",
            "Epoch 20/40\n",
            "20387/20387 [==============================] - 9s 464us/step - loss: 0.0537 - acc: 0.9881\n",
            "Epoch 21/40\n",
            "20387/20387 [==============================] - 9s 464us/step - loss: 0.0532 - acc: 0.9884\n",
            "Epoch 22/40\n",
            "20387/20387 [==============================] - 9s 460us/step - loss: 0.0493 - acc: 0.9894\n",
            "Epoch 23/40\n",
            "20387/20387 [==============================] - 9s 459us/step - loss: 0.0470 - acc: 0.9894\n",
            "Epoch 24/40\n",
            "20387/20387 [==============================] - 10s 466us/step - loss: 0.0451 - acc: 0.9905\n",
            "Epoch 25/40\n",
            "20387/20387 [==============================] - 9s 465us/step - loss: 0.0407 - acc: 0.9909\n",
            "Epoch 26/40\n",
            "20387/20387 [==============================] - 9s 462us/step - loss: 0.0365 - acc: 0.9919\n",
            "Epoch 27/40\n",
            "20387/20387 [==============================] - 9s 458us/step - loss: 0.0348 - acc: 0.9922\n",
            "Epoch 28/40\n",
            "20387/20387 [==============================] - 9s 466us/step - loss: 0.0358 - acc: 0.9921\n",
            "Epoch 29/40\n",
            "20387/20387 [==============================] - 9s 463us/step - loss: 0.0354 - acc: 0.9923\n",
            "Epoch 30/40\n",
            "20387/20387 [==============================] - 9s 459us/step - loss: 0.0306 - acc: 0.9932\n",
            "Epoch 31/40\n",
            "20387/20387 [==============================] - 9s 463us/step - loss: 0.0292 - acc: 0.9934\n",
            "Epoch 32/40\n",
            "20387/20387 [==============================] - 9s 464us/step - loss: 0.0279 - acc: 0.9935\n",
            "Epoch 33/40\n",
            "20387/20387 [==============================] - 9s 461us/step - loss: 0.0266 - acc: 0.9939\n",
            "Epoch 34/40\n",
            "20387/20387 [==============================] - 9s 457us/step - loss: 0.0291 - acc: 0.9942\n",
            "Epoch 35/40\n",
            "20387/20387 [==============================] - 9s 465us/step - loss: 0.0285 - acc: 0.9938\n",
            "Epoch 36/40\n",
            "20387/20387 [==============================] - 13s 625us/step - loss: 0.0241 - acc: 0.9948\n",
            "Epoch 37/40\n",
            "20387/20387 [==============================] - 16s 766us/step - loss: 0.0241 - acc: 0.9947\n",
            "Epoch 38/40\n",
            "20387/20387 [==============================] - 16s 772us/step - loss: 0.0235 - acc: 0.9948\n",
            "Epoch 39/40\n",
            "20387/20387 [==============================] - 16s 772us/step - loss: 0.0218 - acc: 0.9955\n",
            "Epoch 40/40\n",
            "20387/20387 [==============================] - 16s 770us/step - loss: 0.0197 - acc: 0.9964\n",
            "Epoch 1/40\n",
            "20388/20388 [==============================] - 18s 859us/step - loss: 0.1252 - acc: 0.9763\n",
            "Epoch 2/40\n",
            "20388/20388 [==============================] - 16s 774us/step - loss: 0.1146 - acc: 0.9765\n",
            "Epoch 3/40\n",
            "20388/20388 [==============================] - 16s 782us/step - loss: 0.1138 - acc: 0.9765\n",
            "Epoch 4/40\n",
            "20388/20388 [==============================] - 16s 777us/step - loss: 0.1137 - acc: 0.9765\n",
            "Epoch 5/40\n",
            "20388/20388 [==============================] - 16s 774us/step - loss: 0.1143 - acc: 0.9765\n",
            "Epoch 6/40\n",
            "20388/20388 [==============================] - 16s 773us/step - loss: 0.1127 - acc: 0.9765\n",
            "Epoch 7/40\n",
            "20388/20388 [==============================] - 16s 780us/step - loss: 0.1109 - acc: 0.9767\n",
            "Epoch 8/40\n",
            "20388/20388 [==============================] - 11s 541us/step - loss: 0.1114 - acc: 0.9767\n",
            "Epoch 9/40\n",
            "20388/20388 [==============================] - 9s 445us/step - loss: 0.1098 - acc: 0.9770\n",
            "Epoch 10/40\n",
            "20388/20388 [==============================] - 9s 440us/step - loss: 0.1101 - acc: 0.9772\n",
            "Epoch 11/40\n",
            "20388/20388 [==============================] - 9s 438us/step - loss: 0.1064 - acc: 0.9782\n",
            "Epoch 12/40\n",
            "20388/20388 [==============================] - 9s 444us/step - loss: 0.0919 - acc: 0.9802\n",
            "Epoch 13/40\n",
            "20388/20388 [==============================] - 9s 459us/step - loss: 0.0837 - acc: 0.9817\n",
            "Epoch 14/40\n",
            "20388/20388 [==============================] - 11s 517us/step - loss: 0.0769 - acc: 0.9835\n",
            "Epoch 15/40\n",
            "20388/20388 [==============================] - 10s 474us/step - loss: 0.0800 - acc: 0.9832\n",
            "Epoch 16/40\n",
            "20388/20388 [==============================] - 8s 411us/step - loss: 0.0719 - acc: 0.9841\n",
            "Epoch 17/40\n",
            "20388/20388 [==============================] - 8s 405us/step - loss: 0.0721 - acc: 0.9846\n",
            "Epoch 18/40\n",
            "20388/20388 [==============================] - 11s 524us/step - loss: 0.0727 - acc: 0.9852\n",
            "Epoch 19/40\n",
            "20388/20388 [==============================] - 16s 771us/step - loss: 0.0688 - acc: 0.9853\n",
            "Epoch 20/40\n",
            "20388/20388 [==============================] - 16s 772us/step - loss: 0.0687 - acc: 0.9859\n",
            "Epoch 21/40\n",
            "20388/20388 [==============================] - 16s 768us/step - loss: 0.0678 - acc: 0.9867\n",
            "Epoch 22/40\n",
            "20388/20388 [==============================] - 16s 786us/step - loss: 0.0637 - acc: 0.9871\n",
            "Epoch 23/40\n",
            "20388/20388 [==============================] - 16s 772us/step - loss: 0.0621 - acc: 0.9873\n",
            "Epoch 24/40\n",
            "20388/20388 [==============================] - 16s 783us/step - loss: 0.0623 - acc: 0.9867\n",
            "Epoch 25/40\n",
            "20388/20388 [==============================] - 16s 788us/step - loss: 0.0586 - acc: 0.9873\n",
            "Epoch 26/40\n",
            "20388/20388 [==============================] - 16s 785us/step - loss: 0.0618 - acc: 0.9875\n",
            "Epoch 27/40\n",
            "20388/20388 [==============================] - 16s 766us/step - loss: 0.0558 - acc: 0.9884\n",
            "Epoch 28/40\n",
            "20388/20388 [==============================] - 16s 786us/step - loss: 0.0554 - acc: 0.9885\n",
            "Epoch 29/40\n",
            "20388/20388 [==============================] - 16s 776us/step - loss: 0.0548 - acc: 0.9888\n",
            "Epoch 30/40\n",
            "20388/20388 [==============================] - 16s 786us/step - loss: 0.0516 - acc: 0.9893\n",
            "Epoch 31/40\n",
            "20388/20388 [==============================] - 11s 520us/step - loss: 0.0508 - acc: 0.9895\n",
            "Epoch 32/40\n",
            "20388/20388 [==============================] - 9s 430us/step - loss: 0.0501 - acc: 0.9901\n",
            "Epoch 33/40\n",
            "20388/20388 [==============================] - 9s 447us/step - loss: 0.0514 - acc: 0.9895\n",
            "Epoch 34/40\n",
            "20388/20388 [==============================] - 9s 450us/step - loss: 0.0459 - acc: 0.9907\n",
            "Epoch 35/40\n",
            "20388/20388 [==============================] - 9s 443us/step - loss: 0.0477 - acc: 0.9903\n",
            "Epoch 36/40\n",
            "20388/20388 [==============================] - 9s 451us/step - loss: 0.0464 - acc: 0.9909\n",
            "Epoch 37/40\n",
            "20388/20388 [==============================] - 9s 452us/step - loss: 0.0489 - acc: 0.9910\n",
            "Epoch 38/40\n",
            "20388/20388 [==============================] - 9s 447us/step - loss: 0.0479 - acc: 0.9911\n",
            "Epoch 39/40\n",
            "20388/20388 [==============================] - 9s 446us/step - loss: 0.0456 - acc: 0.9906\n",
            "Epoch 40/40\n",
            "20388/20388 [==============================] - 9s 453us/step - loss: 0.0386 - acc: 0.9920\n",
            "Epoch 1/40\n",
            "30581/30581 [==============================] - 15s 479us/step - loss: 0.1038 - acc: 0.9814\n",
            "Epoch 2/40\n",
            "30581/30581 [==============================] - 14s 457us/step - loss: 0.0961 - acc: 0.9817\n",
            "Epoch 3/40\n",
            "30581/30581 [==============================] - 14s 448us/step - loss: 0.0943 - acc: 0.9817\n",
            "Epoch 4/40\n",
            "30581/30581 [==============================] - 14s 448us/step - loss: 0.0945 - acc: 0.9817\n",
            "Epoch 5/40\n",
            "30581/30581 [==============================] - 14s 453us/step - loss: 0.0932 - acc: 0.9818\n",
            "Epoch 6/40\n",
            "30581/30581 [==============================] - 14s 449us/step - loss: 0.0935 - acc: 0.9818\n",
            "Epoch 7/40\n",
            "30581/30581 [==============================] - 14s 461us/step - loss: 0.0934 - acc: 0.9818\n",
            "Epoch 8/40\n",
            "30581/30581 [==============================] - 14s 452us/step - loss: 0.0917 - acc: 0.9818\n",
            "Epoch 9/40\n",
            "30581/30581 [==============================] - 14s 458us/step - loss: 0.0911 - acc: 0.9818\n",
            "Epoch 10/40\n",
            "30581/30581 [==============================] - 14s 470us/step - loss: 0.0863 - acc: 0.9824\n",
            "Epoch 11/40\n",
            "30581/30581 [==============================] - 14s 471us/step - loss: 0.0778 - acc: 0.9839\n",
            "Epoch 12/40\n",
            "30581/30581 [==============================] - 14s 474us/step - loss: 0.0729 - acc: 0.9848\n",
            "Epoch 13/40\n",
            "30581/30581 [==============================] - 14s 467us/step - loss: 0.0650 - acc: 0.9860\n",
            "Epoch 14/40\n",
            "30581/30581 [==============================] - 14s 473us/step - loss: 0.0601 - acc: 0.9869\n",
            "Epoch 15/40\n",
            "30581/30581 [==============================] - 14s 468us/step - loss: 0.0600 - acc: 0.9872\n",
            "Epoch 16/40\n",
            "30581/30581 [==============================] - 15s 474us/step - loss: 0.0569 - acc: 0.9883\n",
            "Epoch 17/40\n",
            "30581/30581 [==============================] - 14s 469us/step - loss: 0.0569 - acc: 0.9885\n",
            "Epoch 18/40\n",
            "30581/30581 [==============================] - 14s 469us/step - loss: 0.0548 - acc: 0.9889\n",
            "Epoch 19/40\n",
            "30581/30581 [==============================] - 15s 477us/step - loss: 0.0535 - acc: 0.9892\n",
            "Epoch 20/40\n",
            "30581/30581 [==============================] - 14s 466us/step - loss: 0.0497 - acc: 0.9899\n",
            "Epoch 21/40\n",
            "30581/30581 [==============================] - 14s 474us/step - loss: 0.0515 - acc: 0.9895\n",
            "Epoch 22/40\n",
            "30581/30581 [==============================] - 14s 468us/step - loss: 0.0473 - acc: 0.9902\n",
            "Epoch 23/40\n",
            "30581/30581 [==============================] - 14s 469us/step - loss: 0.0467 - acc: 0.9903\n",
            "Epoch 24/40\n",
            "30581/30581 [==============================] - 14s 473us/step - loss: 0.0421 - acc: 0.9910\n",
            "Epoch 25/40\n",
            "30581/30581 [==============================] - 14s 466us/step - loss: 0.0420 - acc: 0.9911\n",
            "Epoch 26/40\n",
            "30581/30581 [==============================] - 16s 526us/step - loss: 0.0401 - acc: 0.9915\n",
            "Epoch 27/40\n",
            "30581/30581 [==============================] - 14s 444us/step - loss: 0.0405 - acc: 0.9917\n",
            "Epoch 28/40\n",
            "30581/30581 [==============================] - 14s 467us/step - loss: 0.0397 - acc: 0.9918\n",
            "Epoch 29/40\n",
            "30581/30581 [==============================] - 14s 458us/step - loss: 0.0372 - acc: 0.9917\n",
            "Epoch 30/40\n",
            "30581/30581 [==============================] - 14s 463us/step - loss: 0.0336 - acc: 0.9929\n",
            "Epoch 31/40\n",
            "30581/30581 [==============================] - 14s 460us/step - loss: 0.0346 - acc: 0.9924\n",
            "Epoch 32/40\n",
            "30581/30581 [==============================] - 14s 462us/step - loss: 0.0339 - acc: 0.9927\n",
            "Epoch 33/40\n",
            "30581/30581 [==============================] - 14s 460us/step - loss: 0.0309 - acc: 0.9931\n",
            "Epoch 34/40\n",
            "30581/30581 [==============================] - 14s 458us/step - loss: 0.0301 - acc: 0.9937\n",
            "Epoch 35/40\n",
            "30581/30581 [==============================] - 14s 463us/step - loss: 0.0313 - acc: 0.9931\n",
            "Epoch 36/40\n",
            "30581/30581 [==============================] - 21s 686us/step - loss: 0.0290 - acc: 0.9935\n",
            "Epoch 37/40\n",
            "30581/30581 [==============================] - 24s 774us/step - loss: 0.0286 - acc: 0.9939\n",
            "Epoch 38/40\n",
            "30581/30581 [==============================] - 23s 768us/step - loss: 0.0287 - acc: 0.9939\n",
            "Epoch 39/40\n",
            "30581/30581 [==============================] - 24s 777us/step - loss: 0.0271 - acc: 0.9945\n",
            "Epoch 40/40\n",
            "30581/30581 [==============================] - 24s 774us/step - loss: 0.0247 - acc: 0.9948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i_sHRwZ5UZ9h",
        "colab_type": "code",
        "outputId": "a0a58376-8f54-4ab2-bad2-a2d614b57e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)\n",
        "\n",
        "best_model = validator.best_estimator_.model\n",
        "metric_names = best_model.metrics_names\n",
        "metric_values = best_model.evaluate(X_test, y_test)\n",
        "for metric, value in zip(metric_names, metric_values):\n",
        "  print(metric, ': ', value)\n",
        "  \n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters of the best model are: \n",
            "{'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 40, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n",
            "10793/10793 [==============================] - 3s 315us/step\n",
            "loss :  0.29735768614736047\n",
            "acc :  0.9657185212637821\n",
            "-0.151057 (0.081238) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 40, 'filters': 20, 'kernel_size': (3, 3), 'pool_size': (2, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NvvRbL1KPSSK",
        "colab_type": "code",
        "outputId": "21c38eff-388d-4a2f-fbdb-6629e2cba21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate AUC of final model on a test set\n",
        "probs = best_model.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "#probs = probs[:, 1]\n",
        "y_test2 = numpy.load('drive/My Drive/y_test.npy')  # osobno, bo inny wymiar\n",
        "\n",
        "auc = roc_auc_score(y_test2, probs)\n",
        "print('AUC: %.3f' % auc)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, probs)\n",
        "# plot no skill\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr, tpr, marker='.')\n",
        "# show the plot\n",
        "plt.title('ROC curve for test set')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFJ8n9EZofoqqZ5IQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2e2df88198>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aOXKJUC-bjnb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}